<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>About Us</title>
  <style>
    :root {
      --primary-color: #457D58;
      --secondary-color: #CBDDD1;
      --dark-color: #272727;
      --light-color: white;
    }

    body {
      margin: 0;
      font-family: Arial, sans-serif;
      background-color: var(--light-color);
      color: var(--dark-color);
      line-height: 1.6;
      padding: 2rem;
    }

    header {
      text-align: center;
      margin-bottom: 2rem;
    }

    header h1 {
      font-size: 2.5rem;
      color: var(--primary-color);
    }

    section {
      max-width: 800px;
      margin: 0 auto;
      background-color: var(--secondary-color);
      padding: 1.5rem;
      border-radius: 10px;
      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }

    section h2 {
      color: var(--dark-color);
      margin-bottom: 1rem;
    }

    section p {
      margin-bottom: 1rem;
    }

    footer {
      text-align: center;
      margin-top: 2rem;
    }

    footer a {
      color: var(--primary-color);
      text-decoration: none;
      font-weight: bold;
    }

    footer a:hover {
      color: var(--dark-color);
    }
  </style>
</head>
<body>
  <header>
    <h1>About Us</h1>
  </header>
  <section>
    <h2>BlackBoxScan</h2>
    <p>
      Open-sourced AI is the only way to ensure inclusivity.
We had noticed how curious members from other fields (biology, anthropology, law, business, economics, etc.) were very keen on exploring AI models and its applications in their particular fields of research/industry. However, they were having a hard time not only writing code to access these models, but also knowing what different interpretability techniques they can apply to such models. 
Which is why, we came up with BlackBoxScan. It is an open-source project which showcases various AI explainability and interpretability techniques that can be implemented with just 1-2 lines of calls to the library.
    </p>
    <h2>How You Can Help</h2>
    <p>
      If you are keenly interested in AI applications into your field, we would love for you to try BlackBoxScan and reach back out to us with feedback (we read each one of them), as well as ideas to improve offerings.
      If you are an AI Researcher/Engineer who wishes to contribute your own interpretability techniques to help expand the repository, feel free to send a PR or a message sharing your ideas, and we will implement them.
  </br>
      We are looking to expand this repository into: 
  </br>
    1. More nuanced techniques for better visualisation/presentation of results.
    2. Multi-modal models, starting with image models.
    </p>
    <h2>Future Vision</h2>
    <p>
      We vision this to eventually become a massive repo which is able to incorporate all the SOTA interpretability techniques that keep being researched by top researchers around the world.
      This could be a place where people can easily access latest AI research techniques and apply it to their specific use cases.
    </p>
  </section>
  <footer>
    <p>
      <a href="index.html">Back to Home</a>
    </p>
  </footer>
</body>
</html>
